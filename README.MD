# Govorne Tehnologije
## Generisanje sadržaja wikipedije korišćenjem GPT-2 modela

Namera ovog projekta je da iskoristi arhitekturu modela GPT-2 za treniranje na sadržaju srpske Wikipedije, s fokusom na korišćenje ćiriličnog pisma. Cilj je istraživanje primene savremenih metoda generisanja teksta na srpskom jeziku, posebno na ćirilici.

### REFERENCE
- [Implementacija GPT-2](https://github.com/karpathy/nanoGPT)
- [Implementacija BPE](https://github.com/karpathy/minbpe)
- [Perplexity metrika](https://huggingface.co/docs/transformers/en/perplexity)
